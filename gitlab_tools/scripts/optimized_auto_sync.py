#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆè‡ªåŠ¨åŒ–åŒæ­¥è„šæœ¬
é›†æˆæ™ºèƒ½å˜æ›´æ£€æµ‹å’Œé˜Ÿåˆ—å¤„ç†
"""

import sys
import time
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Union

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from gitlab_tools.core.change_detector import ChangeDetector
from gitlab_tools.core.smart_queue_processor import SmartQueueProcessor
from gitlab_tools.core.database_manager import DatabaseManager
from gitlab_tools.utils.helpers import setup_logging

class OptimizedAutoSync:
    """ä¼˜åŒ–ç‰ˆè‡ªåŠ¨åŒ–åŒæ­¥å™¨"""

    def __init__(self):
        self.change_detector = ChangeDetector()
        self.queue_processor = SmartQueueProcessor()
        self.db_manager = DatabaseManager()
        self.logger = setup_logging('optimized_auto_sync')

    def run_single_sync(self, batch_size: int = 10) -> Dict:
        """è¿è¡Œå•æ¬¡åŒæ­¥"""
        self.logger.info("ğŸš€ å¼€å§‹ä¼˜åŒ–ç‰ˆå•æ¬¡åŒæ­¥...")

        start_time = datetime.now()
        results = {
            'changes_detected': 0,
            'queue_processed': {'processed': 0, 'success': 0, 'failed': 0},
            'duration': 0
        }

        try:
            # 1. æ£€æµ‹å˜æ›´
            self.logger.info("ğŸ” æ£€æµ‹æ•°æ®åº“å˜æ›´...")
            changes_count = self.change_detector.run_single_check()
            results['changes_detected'] = changes_count

            # 2. å¤„ç†é˜Ÿåˆ—
            self.logger.info("ğŸ”„ å¤„ç†åŒæ­¥é˜Ÿåˆ—...")
            queue_result = self.queue_processor.process_batch(batch_size)
            results['queue_processed'] = queue_result

            # 3. è®¡ç®—è€—æ—¶
            duration = (datetime.now() - start_time).total_seconds()
            results['duration'] = duration

            self.logger.info(f"âœ… åŒæ­¥å®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            self.logger.info(f"ğŸ“Š å˜æ›´æ£€æµ‹: {changes_count} ä¸ª")
            self.logger.info(f"ğŸ“Š é˜Ÿåˆ—å¤„ç†: {queue_result}")

        except Exception as e:
            self.logger.error(f"âŒ åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            results['error'] = str(e)

        return results

    def run_continuous_sync(self, interval: int = 30, batch_size: int = 10):
        """è¿è¡ŒæŒç»­åŒæ­¥"""
        self.logger.info(f"ğŸ”„ å¼€å§‹æŒç»­åŒæ­¥æ¨¡å¼ï¼Œé—´éš”: {interval}ç§’")

        try:
            while True:
                # è¿è¡Œå•æ¬¡åŒæ­¥
                result = self.run_single_sync(batch_size)

                # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                self._log_sync_statistics(result)

                # ç­‰å¾…ä¸‹æ¬¡åŒæ­¥
                self.logger.info(f"â° ç­‰å¾… {interval} ç§’åè¿›è¡Œä¸‹æ¬¡åŒæ­¥...")
                time.sleep(interval)

        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ æŒç»­åŒæ­¥å·²åœæ­¢")
        except Exception as e:
            self.logger.error(f"âŒ æŒç»­åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

    def run_change_monitoring(self, interval: int = 10):
        """è¿è¡Œå˜æ›´ç›‘æ§æ¨¡å¼"""
        self.logger.info(f"ğŸ‘ï¸ å¼€å§‹å˜æ›´ç›‘æ§æ¨¡å¼ï¼Œé—´éš”: {interval}ç§’")

        try:
            self.change_detector.run_continuous_monitoring(interval)
        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ å˜æ›´ç›‘æ§å·²åœæ­¢")
        except Exception as e:
            self.logger.error(f"âŒ å˜æ›´ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

    def run_queue_processing(self, interval: int = 60, batch_size: int = 10):
        """è¿è¡Œé˜Ÿåˆ—å¤„ç†æ¨¡å¼"""
        self.logger.info(f"âš™ï¸ å¼€å§‹é˜Ÿåˆ—å¤„ç†æ¨¡å¼ï¼Œé—´éš”: {interval}ç§’")

        try:
            while True:
                # å¤„ç†é˜Ÿåˆ—
                result = self.queue_processor.process_batch(batch_size)

                if result['processed'] > 0:
                    self.logger.info(f"ğŸ“Š é˜Ÿåˆ—å¤„ç†ç»“æœ: {result}")
                else:
                    self.logger.info("âœ… é˜Ÿåˆ—ä¸ºç©ºï¼Œæ— éœ€å¤„ç†")

                # ç­‰å¾…ä¸‹æ¬¡å¤„ç†
                time.sleep(interval)

        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ é˜Ÿåˆ—å¤„ç†å·²åœæ­¢")
        except Exception as e:
            self.logger.error(f"âŒ é˜Ÿåˆ—å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        try:
            # è·å–é˜Ÿåˆ—çŠ¶æ€
            queue_status = self.queue_processor.get_queue_status()

            # è·å–æ•°æ®åº“ç»Ÿè®¡
            db_stats = self._get_database_stats()

            # è·å–æœ€è¿‘åŒæ­¥ç»Ÿè®¡
            sync_stats = self._get_sync_statistics()

            return {
                'queue_status': queue_status,
                'database_stats': db_stats,
                'sync_statistics': sync_stats,
                'timestamp': datetime.now().isoformat()
            }

        except Exception as e:
            self.logger.error(f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def _get_database_stats(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡"""
        try:
            query = """
                SELECT
                    COUNT(*) as total_issues,
                    COUNT(CASE WHEN status = 'open' THEN 1 END) as open_issues,
                    COUNT(CASE WHEN status = 'closed' THEN 1 END) as closed_issues,
                    COUNT(CASE WHEN gitlab_url IS NOT NULL AND gitlab_url != '' THEN 1 END) as synced_issues
                FROM issues
            """

            result = self.db_manager.execute_query(query)
            return result[0] if result else {}

        except Exception as e:
            return {'error': str(e)}

    def _get_sync_statistics(self) -> Union[List[Dict[str, Any]], Dict[str, str]]:
        """è·å–åŒæ­¥ç»Ÿè®¡"""
        try:
            query = """
                SELECT
                    action_type,
                    SUM(success_count) as total_success,
                    SUM(failure_count) as total_failure,
                    AVG(avg_processing_time) as avg_time
                FROM sync_statistics
                WHERE date >= DATE_SUB(NOW(), INTERVAL 7 DAY)
                GROUP BY action_type
            """

            result = self.db_manager.execute_query(query)
            return result if result else []

        except Exception as e:
            return {'error': str(e)}

    def _log_sync_statistics(self, result: Dict):
        """è®°å½•åŒæ­¥ç»Ÿè®¡"""
        try:
            # è¿™é‡Œå¯ä»¥æ·»åŠ ç»Ÿè®¡è®°å½•é€»è¾‘
            pass
        except Exception as e:
            self.logger.error(f"âš ï¸ è®°å½•ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")

    def cleanup_system(self, days_to_keep: int = 30):
        """æ¸…ç†ç³»ç»Ÿæ•°æ®"""
        self.logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†ç³»ç»Ÿæ•°æ®ï¼Œä¿ç•™ {days_to_keep} å¤©...")

        try:
            # æ¸…ç†é˜Ÿåˆ—æ•°æ®
            self.queue_processor.cleanup_old_tasks(days_to_keep)

            # æ¸…ç†å˜æ›´æ—¥å¿—
            query = f"""
                DELETE FROM issue_changes
                WHERE change_timestamp < DATE_SUB(NOW(), INTERVAL {days_to_keep} DAY)
                AND processed = TRUE
            """
            self.db_manager.execute_update(query)

            self.logger.info("âœ… ç³»ç»Ÿæ¸…ç†å®Œæˆ")

        except Exception as e:
            self.logger.error(f"âŒ ç³»ç»Ÿæ¸…ç†å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–ç‰ˆè‡ªåŠ¨åŒ–åŒæ­¥è„šæœ¬')
    parser.add_argument('mode', choices=[
        'single', 'continuous', 'monitor', 'queue', 'status', 'cleanup'
    ], help='è¿è¡Œæ¨¡å¼')

    parser.add_argument('--interval', type=int, default=30,
                       help='æŒç»­æ¨¡å¼é—´éš”ï¼ˆç§’ï¼‰')
    parser.add_argument('--batch-size', type=int, default=10,
                       help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--days', type=int, default=30,
                       help='æ¸…ç†æ—¶ä¿ç•™çš„å¤©æ•°')

    args = parser.parse_args()

    sync = OptimizedAutoSync()

    if args.mode == 'single':
        result = sync.run_single_sync(args.batch_size)
        print(f"ğŸ“Š åŒæ­¥ç»“æœ: {result}")

    elif args.mode == 'continuous':
        sync.run_continuous_sync(args.interval, args.batch_size)

    elif args.mode == 'monitor':
        sync.run_change_monitoring(args.interval)

    elif args.mode == 'queue':
        sync.run_queue_processing(args.interval, args.batch_size)

    elif args.mode == 'status':
        status = sync.get_system_status()
        print("ğŸ“‹ ç³»ç»ŸçŠ¶æ€:")
        print(f"  é˜Ÿåˆ—çŠ¶æ€: {status.get('queue_status', {})}")
        print(f"  æ•°æ®åº“ç»Ÿè®¡: {status.get('database_stats', {})}")
        print(f"  åŒæ­¥ç»Ÿè®¡: {status.get('sync_statistics', {})}")

    elif args.mode == 'cleanup':
        sync.cleanup_system(args.days)

if __name__ == "__main__":
    main()
