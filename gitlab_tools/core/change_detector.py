#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½å˜æ›´æ£€æµ‹å™¨
æ£€æµ‹æ•°æ®åº“å˜æ›´å¹¶è‡ªåŠ¨è§¦å‘åŒæ­¥
"""

import hashlib
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from database_manager import DatabaseManager
from gitlab_operations import GitLabOperations

@dataclass
class ChangeEvent:
    """å˜æ›´äº‹ä»¶"""
    issue_id: int
    change_type: str  # INSERT, UPDATE, DELETE
    field_name: str
    old_value: Any
    new_value: Any
    timestamp: datetime
    hash_value: str

class ChangeDetector:
    """æ™ºèƒ½å˜æ›´æ£€æµ‹å™¨"""

    def __init__(self):
        self.db_manager = DatabaseManager()
        self.gitlab_ops = GitLabOperations()
        self.last_check_time = None
        self.change_cache = {}

    def calculate_hash(self, issue_data: Dict[str, Any]) -> str:
        """è®¡ç®—è®®é¢˜æ•°æ®å“ˆå¸Œå€¼"""
        # é€‰æ‹©å…³é”®å­—æ®µè¿›è¡Œå“ˆå¸Œè®¡ç®—
        key_fields = [
            'project_name',
            'problem_description',
            'status',
            'responsible_person',
            'severity_level',
            'problem_category'
        ]

        hash_data = {}
        for field in key_fields:
            hash_data[field] = str(issue_data.get(field, ''))

        # åˆ›å»ºå“ˆå¸Œ
        hash_string = json.dumps(hash_data, sort_keys=True)
        return hashlib.md5(hash_string.encode()).hexdigest()

    def detect_changes(self, since: Optional[datetime] = None) -> List[ChangeEvent]:
        """æ£€æµ‹æ•°æ®åº“å˜æ›´"""
        if since is None:
            since = datetime.now() - timedelta(minutes=5)

        changes = []

        # æŸ¥è¯¢æœ€è¿‘ä¿®æ”¹çš„è®®é¢˜
        query = """
            SELECT id, project_name, problem_description, status, responsible_person,
                   severity_level, problem_category, gitlab_url, updated_at
            FROM issues
            WHERE updated_at > %s
            ORDER BY updated_at ASC
        """

        recent_issues = self.db_manager.execute_query(query.replace('%s', f"'{since}'"))

        for issue in recent_issues:
            issue_id = issue['id']
            current_hash = self.calculate_hash(issue)

            # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
            if issue_id in self.change_cache:
                old_hash = self.change_cache[issue_id]
                if old_hash != current_hash:
                    # æ£€æµ‹åˆ°å˜æ›´
                    change_event = ChangeEvent(
                        issue_id=issue_id,
                        change_type='UPDATE',
                        field_name='data_hash',
                        old_value=old_hash,
                        new_value=current_hash,
                        timestamp=issue['updated_at'],
                        hash_value=current_hash
                    )
                    changes.append(change_event)
            else:
                # æ–°è®®é¢˜
                change_event = ChangeEvent(
                    issue_id=issue_id,
                    change_type='INSERT',
                    field_name='data_hash',
                    old_value=None,
                    new_value=current_hash,
                    timestamp=issue['updated_at'],
                    hash_value=current_hash
                )
                changes.append(change_event)

            # æ›´æ–°ç¼“å­˜
            self.change_cache[issue_id] = current_hash

        return changes

    def should_sync_issue(self, issue_data: Dict[str, Any]) -> tuple[bool, str]:
        """åˆ¤æ–­è®®é¢˜æ˜¯å¦éœ€è¦åŒæ­¥"""
        status = issue_data.get('status', '')
        gitlab_url = issue_data.get('gitlab_url', '')

        # æ£€æŸ¥çŠ¶æ€å˜æ›´
        if status == 'closed' and gitlab_url:
            return True, 'close'
        elif status == 'open' and not gitlab_url:
            return True, 'create'
        elif status == 'open' and gitlab_url:
            return True, 'update'
        elif gitlab_url:
            return True, 'sync_progress'

        return False, ''

    def add_to_sync_queue(self, issue_id: int, action: str, priority: int = 5, metadata: Optional[Dict] = None):
        """æ·»åŠ ä»»åŠ¡åˆ°åŒæ­¥é˜Ÿåˆ—"""
        try:
            # ä½¿ç”¨å­˜å‚¨è¿‡ç¨‹æ·»åŠ ä»»åŠ¡
            query = "CALL AddToSyncQueue(%s, %s, %s, %s)"
            metadata_json = json.dumps(metadata if metadata is not None else {})

            result = self.db_manager.execute_query(query.format(issue_id, action, priority, metadata_json))

            if result:
                queue_id = result[0].get('queue_id', 0)
                result_type = result[0].get('result', 'unknown')

                print(f"âœ… ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—: ID={queue_id}, ç»“æœ={result_type}")
                return queue_id
            else:
                print(f"âŒ æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—å¤±è´¥")
                return None

        except Exception as e:
            print(f"âŒ æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return None

    def process_changes(self, changes: List[ChangeEvent]):
        """å¤„ç†æ£€æµ‹åˆ°çš„å˜æ›´"""
        for change in changes:
            try:
                # è·å–è®®é¢˜è¯¦æƒ…
                issue_data = self.db_manager.get_issue_by_id(change.issue_id)
                if not issue_data:
                    continue

                # åˆ¤æ–­æ˜¯å¦éœ€è¦åŒæ­¥
                should_sync, action = self.should_sync_issue(issue_data)

                if should_sync:
                    # ç¡®å®šä¼˜å…ˆçº§
                    priority = self._determine_priority(issue_data, action)

                    # å‡†å¤‡å…ƒæ•°æ®
                    metadata = {
                        'change_type': change.change_type,
                        'field_name': change.field_name,
                        'timestamp': change.timestamp.isoformat(),
                        'hash_value': change.hash_value
                    }

                    # æ·»åŠ åˆ°åŒæ­¥é˜Ÿåˆ—
                    queue_id = self.add_to_sync_queue(
                        change.issue_id,
                        action,
                        priority,
                        metadata
                    )

                    if queue_id:
                        print(f"ğŸ”„ è®®é¢˜ #{change.issue_id} å·²åŠ å…¥åŒæ­¥é˜Ÿåˆ—: {action}")

            except Exception as e:
                print(f"âŒ å¤„ç†å˜æ›´æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    def _determine_priority(self, issue_data: Dict[str, Any], action: str) -> int:
        """ç¡®å®šåŒæ­¥ä¼˜å…ˆçº§"""
        # åŸºç¡€ä¼˜å…ˆçº§
        priority_map = {
            'create': 3,      # åˆ›å»ºè®®é¢˜ä¼˜å…ˆçº§è¾ƒé«˜
            'close': 2,      # å…³é—­è®®é¢˜ä¼˜å…ˆçº§æœ€é«˜
            'update': 4,     # æ›´æ–°è®®é¢˜
            'sync_progress': 5  # åŒæ­¥è¿›åº¦ä¼˜å…ˆçº§è¾ƒä½
        }

        base_priority = priority_map.get(action, 5)

        # æ ¹æ®ä¸¥é‡ç¨‹åº¦è°ƒæ•´ä¼˜å…ˆçº§
        severity = issue_data.get('severity_level', 0)
        if isinstance(severity, (int, float)) and severity > 0:
            if severity >= 3:
                base_priority = max(1, base_priority - 1)  # æé«˜ä¼˜å…ˆçº§
            elif severity <= 1:
                base_priority = min(10, base_priority + 1)  # é™ä½ä¼˜å…ˆçº§

        return base_priority

    def run_continuous_monitoring(self, interval: int = 30):
        """æŒç»­ç›‘æ§æ¨¡å¼"""
        print(f"ğŸ”„ å¼€å§‹æŒç»­ç›‘æ§æ¨¡å¼ï¼Œæ£€æŸ¥é—´éš”: {interval}ç§’")

        while True:
            try:
                # æ£€æµ‹å˜æ›´
                changes = self.detect_changes()

                if changes:
                    print(f"ğŸ“‹ æ£€æµ‹åˆ° {len(changes)} ä¸ªå˜æ›´")
                    self.process_changes(changes)
                else:
                    print("âœ… æ— å˜æ›´æ£€æµ‹åˆ°")

                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(interval)

            except KeyboardInterrupt:
                print("\nğŸ›‘ ç›‘æ§å·²åœæ­¢")
                break
            except Exception as e:
                print(f"âŒ ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                time.sleep(interval)

    def run_single_check(self):
        """å•æ¬¡æ£€æŸ¥æ¨¡å¼"""
        print("ğŸ” æ‰§è¡Œå•æ¬¡å˜æ›´æ£€æµ‹...")

        changes = self.detect_changes()

        if changes:
            print(f"ğŸ“‹ æ£€æµ‹åˆ° {len(changes)} ä¸ªå˜æ›´:")
            for change in changes:
                print(f"  - è®®é¢˜ #{change.issue_id}: {change.change_type}")

            self.process_changes(changes)
        else:
            print("âœ… æ— å˜æ›´æ£€æµ‹åˆ°")

        return len(changes)

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='æ™ºèƒ½å˜æ›´æ£€æµ‹å™¨')
    parser.add_argument('mode', choices=['single', 'continuous'], help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--interval', type=int, default=30, help='æŒç»­æ¨¡å¼æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰')

    args = parser.parse_args()

    detector = ChangeDetector()

    if args.mode == 'single':
        detector.run_single_check()
    elif args.mode == 'continuous':
        detector.run_continuous_monitoring(args.interval)

if __name__ == "__main__":
    main()
