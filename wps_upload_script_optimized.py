#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WPSè¡¨æ ¼ä¸Šä¼ è„šæœ¬ - ä¼˜åŒ–ç‰ˆ
ä¸“é—¨å¤„ç†åŒ…å«"è½¯ä»¶"å…³é”®è¯çš„é—®é¢˜åˆ†ç±»æ•°æ®
åœ¨WPSç¯å¢ƒä¸‹è¿è¡Œï¼Œè´Ÿè´£æ•°æ®ä¸Šä¼ åˆ°æœåŠ¡å™¨
ä¼˜åŒ–äº†æ—¥å¿—è®°å½•å’Œç”¨æˆ·ä½“éªŒ
"""

import requests
import time
from datetime import datetime
from typing import Dict, List, Any

# ==================== é…ç½®ä¿¡æ¯ ====================
CONFIG = {
    'server_url': 'http://114.55.118.105/api/wps/upload',
    'target_category': 'è½¯ä»¶',
    'batch_size': 50,
    'timeout': 30,
    'sheet_names': ['è½¯ä»¶ç®—æ³•æ±‡æ€»', 'é—®é¢˜æ¸…å•', 'è®®é¢˜æ¸…å•', 'é—®é¢˜æ±‡æ€»'],
    'process_all_sheets': True,
    'target_sheet': None,
    'software_keywords': ['è½¯ä»¶'],
    'filter_mode': 'software',
    'debug_mode': False,  # æ–°å¢ï¼šè°ƒè¯•æ¨¡å¼å¼€å…³
    'show_progress': True,  # æ–°å¢ï¼šæ˜¾ç¤ºè¿›åº¦æ¡
    'log_level': 'INFO'  # æ–°å¢ï¼šæ—¥å¿—çº§åˆ«
}

class Logger:
    """æ—¥å¿—ç®¡ç†å™¨"""

    def __init__(self, level: str = 'INFO'):
        self.level = level
        self.levels = {'DEBUG': 0, 'INFO': 1, 'WARNING': 2, 'ERROR': 3}
        self.start_time = time.time()

    def _should_log(self, level: str) -> bool:
        return self.levels.get(level, 1) >= self.levels.get(self.level, 1)

    def debug(self, message: str):
        if self._should_log('DEBUG'):
            print(f"ğŸ” [DEBUG] {message}")

    def info(self, message: str):
        if self._should_log('INFO'):
            print(f"â„¹ï¸  [INFO] {message}")

    def warning(self, message: str):
        if self._should_log('WARNING'):
            print(f"âš ï¸  [WARN] {message}")

    def error(self, message: str):
        if self._should_log('ERROR'):
            print(f"âŒ [ERROR] {message}")

    def success(self, message: str):
        print(f"âœ… [SUCCESS] {message}")

    def get_elapsed_time(self) -> str:
        elapsed = time.time() - self.start_time
        return f"{elapsed:.2f}s"

# å…¨å±€æ—¥å¿—å™¨
logger = Logger(CONFIG['log_level'])

def is_empty_value(value):
    """åˆ¤æ–­å€¼æ˜¯å¦ä¸ºç©º"""
    if value is None:
        return True
    str_value = str(value).strip().lower()
    return str_value in ['', 'nan', 'none', 'null']

def clean_string_value(value):
    """æ¸…ç†å­—ç¬¦ä¸²å€¼"""
    if is_empty_value(value):
        return ''
    return str(value).strip()

def is_valid_software_record(problem_category):
    """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è½¯ä»¶è®°å½•"""
    if is_empty_value(problem_category):
        return False
    category = clean_string_value(problem_category)
    return 'è½¯ä»¶' in category

def is_valid_record(problem_category, filter_mode):
    """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆè®°å½•"""
    if is_empty_value(problem_category):
        return False

    if filter_mode == 'all':
        return True
    elif filter_mode == 'software':
        return is_valid_software_record(problem_category)
    else:
        return True

def transform_record(row_data):
    """è½¬æ¢å•æ¡è®°å½•"""
    record = {}

    field_mapping = {
        'é¡¹ç›®åç§°': 'project_name',
        'é—®é¢˜åˆ†ç±»': 'problem_category',
        'ä¸¥é‡ç¨‹åº¦': 'severity_level',
        'é—®é¢˜/éœ€æ±‚æè¿°': 'problem_description',
        'è§£å†³æ–¹æ¡ˆ': 'solution',
        'è¡ŒåŠ¨ä¼˜å…ˆçº§': 'action_priority',
        'è¡ŒåŠ¨è®°å½•': 'action_record',
        'å‘èµ·äºº': 'initiator',
        'è´£ä»»äºº': 'responsible_person',
        'çŠ¶æ€': 'status',
        'å¼€å§‹æ—¶é—´': 'start_time',
        'ç›®æ ‡å®Œæˆæ—¶é—´': 'target_completion_time',
        'å®å®Œæ—¶é—´': 'actual_completion_time',
        'å¤‡æ³¨': 'remarks'
    }

    for source_field, target_field in field_mapping.items():
        value = row_data.get(source_field, '')
        record[target_field] = clean_string_value(value)

    return record

def show_progress(current: int, total: int, prefix: str = "è¿›åº¦"):
    """æ˜¾ç¤ºè¿›åº¦æ¡"""
    if not CONFIG['show_progress']:
        return

    percent = (current / total) * 100
    bar_length = 30
    filled_length = int(bar_length * current // total)
    bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)

    print(f"\r{prefix}: |{bar}| {current}/{total} ({percent:.1f}%)", end='', flush=True)

    if current == total:
        print()  # æ¢è¡Œ

def upload_batch(batch_data, batch_num, total_batches):
    """ä¸Šä¼ å•æ‰¹æ•°æ®"""
    logger.info(f"ä¸Šä¼ ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch_data)} æ¡)")

    # è°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
    if CONFIG['debug_mode'] and batch_data and batch_num == 1:
        logger.debug(f"ç¬¬ä¸€æ¡æ•°æ®å­—æ®µ: {list(batch_data[0].keys())}")
        logger.debug(f"ç¬¬ä¸€æ¡æ•°æ®å†…å®¹: {batch_data[0]}")

    upload_payload = {
        'table_data': batch_data,
        'client_info': {
            'version': '2.2.0',  # æ›´æ–°ç‰ˆæœ¬å·
            'timestamp': datetime.now().isoformat(),
            'batch_info': {
                'current_batch': batch_num,
                'total_batches': total_batches,
                'batch_size': len(batch_data)
            },
            'source': 'WPSè¡¨æ ¼-ä¼˜åŒ–ç‰ˆ'
        }
    }

    try:
        start_time = time.time()
        response = requests.post(
            CONFIG['server_url'],
            json=upload_payload,
            headers={'Content-Type': 'application/json'},
            timeout=CONFIG['timeout']
        )
        upload_time = time.time() - start_time

        if response.status_code == 200:
            result = response.json()

            # è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºå®Œæ•´å“åº”
            if CONFIG['debug_mode']:
                logger.debug(f"æœåŠ¡å™¨å“åº”: {result}")

            if result.get('success'):
                stats = result.get('statistics', {})
                success_count = stats.get('success', 0)
                skipped_count = stats.get('skipped', 0)  # æ–°å¢ï¼šè·å–è·³è¿‡è®¡æ•°
                failed_count = stats.get('failed', 0)

                # ä¼˜åŒ–åçš„æ˜¾ç¤ºé€»è¾‘
                if success_count > 0 or skipped_count > 0:
                    logger.success(f"ç¬¬ {batch_num} æ‰¹å¤„ç†å®Œæˆ ({upload_time:.2f}s)")
                    if success_count > 0:
                        logger.success(f"  âœ… æ–°å¢: {success_count} æ¡")
                    if skipped_count > 0:
                        logger.info(f"  â­ï¸  è·³è¿‡: {skipped_count} æ¡ (æ•°æ®å·²å­˜åœ¨)")
                    if failed_count > 0:
                        logger.warning(f"  âŒ å¤±è´¥: {failed_count} æ¡")

                    # è¿”å›ç»Ÿè®¡ä¿¡æ¯å­—å…¸
                    return {'success': success_count, 'skipped': skipped_count, 'failed': failed_count}
                else:
                    logger.warning(f"ç¬¬ {batch_num} æ‰¹æ— æœ‰æ•ˆæ•°æ®")
                    return {'success': 0, 'skipped': 0, 'failed': failed_count}
            else:
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                errors = result.get('errors', [])
                logger.error(f"ç¬¬ {batch_num} æ‰¹ä¸šåŠ¡å¤±è´¥: {error_msg}")

                # æ˜¾ç¤ºå‰3ä¸ªé”™è¯¯è¯¦æƒ…
                for i, error in enumerate(errors[:3], 1):
                    logger.error(f"  é”™è¯¯ {i}: {error}")

                if len(errors) > 3:
                    logger.error(f"  ... è¿˜æœ‰ {len(errors) - 3} ä¸ªé”™è¯¯")

                return None
        else:
            logger.error(f"ç¬¬ {batch_num} æ‰¹ä¸Šä¼ å¤±è´¥: HTTP {response.status_code}")
            if CONFIG['debug_mode']:
                logger.debug(f"é”™è¯¯å“åº”: {response.text}")
            return None

    except Exception as e:
        logger.error(f"ç¬¬ {batch_num} æ‰¹ä¸Šä¼ å¼‚å¸¸: {e}")
        return None

def get_database_status():
    """è·å–æ•°æ®åº“çŠ¶æ€ä¿¡æ¯"""
    logger.info("è·å–æ•°æ®åº“çŠ¶æ€ä¿¡æ¯")

    try:
        response = requests.get(
            'http://114.55.118.105/api/database/status',
            timeout=CONFIG['timeout']
        )

        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                data = result.get('data', {})
                logger.info(f"æ•°æ®åº“çŠ¶æ€: æ€»è®®é¢˜ {data.get('total_issues', 0)}, "
                          f"å¼€æ”¾ {data.get('open_issues', 0)}, "
                          f"å…³é—­ {data.get('closed_issues', 0)}, "
                          f"å·²åŒæ­¥ {data.get('synced_issues', 0)}")
                return True
            else:
                logger.error(f"è·å–çŠ¶æ€å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
        else:
            logger.error(f"çŠ¶æ€è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
            return False

    except Exception as e:
        logger.error(f"è·å–çŠ¶æ€å¼‚å¸¸: {e}")
        return False

def read_sheet_data(sheet_name):
    """è¯»å–æŒ‡å®šå·¥ä½œè¡¨çš„æ•°æ®"""
    try:
        logger.info(f"è¯»å–å·¥ä½œè¡¨: '{sheet_name}'")
        df = xl('$B:$P', headers=True, sheet_name=sheet_name)  # type: ignore
        if df is not None and not df.empty:
            logger.success(f"æˆåŠŸè¯»å–å·¥ä½œè¡¨: '{sheet_name}' - {len(df)} è¡Œæ•°æ®")
            return df
        else:
            logger.warning(f"å·¥ä½œè¡¨ '{sheet_name}' ä¸ºç©ºæˆ–æ— æ³•è¯»å–")
            return None
    except Exception as e:
        logger.error(f"è¯»å–å·¥ä½œè¡¨ '{sheet_name}' å¤±è´¥: {e}")
        return None

def process_sheet_data(df, sheet_name):
    """å¤„ç†å•ä¸ªå·¥ä½œè¡¨çš„æ•°æ®"""
    logger.info(f"å¤„ç†å·¥ä½œè¡¨: '{sheet_name}'")

    # æ¸…æ´—æ•°æ®
    logger.debug("æ¸…æ´—æ•°æ®")
    df = df.dropna(how='all').reset_index(drop=True)

    # æ¸…ç†å­—ç¬¦ä¸²åˆ—
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].fillna('').astype(str)
            df[col] = df[col].replace(['nan', 'NaN', 'null', 'None', 'NULL'], '')
            df[col] = df[col].str.strip()

    # ç­›é€‰æœ‰æ•ˆè®°å½•
    logger.debug("ç­›é€‰æœ‰æ•ˆè®°å½•")
    valid_records = []

    for _, row in df.iterrows():
        problem_category = clean_string_value(row.get('é—®é¢˜åˆ†ç±»', ''))
        project_name = clean_string_value(row.get('é¡¹ç›®åç§°', ''))

        # è·³è¿‡ç©ºè¡Œ
        if is_empty_value(problem_category) and is_empty_value(project_name):
            continue

        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆè®°å½•
        if is_valid_record(problem_category, CONFIG['filter_mode']):
            try:
                row_dict = row.to_dict() if hasattr(row, 'to_dict') else dict(row)
                record = transform_record(row_dict)

                # éªŒè¯å¿…å¡«å­—æ®µ
                if not record.get('project_name'):
                    continue

                # å¦‚æœæ²¡æœ‰é—®é¢˜åˆ†ç±»ï¼Œè®¾ç½®é»˜è®¤å€¼
                if not record.get('problem_category'):
                    record['problem_category'] = 'å…¶ä»–'

                # æ·»åŠ æ¥æºå·¥ä½œè¡¨ä¿¡æ¯
                record['source_sheet'] = sheet_name

                valid_records.append(record)

            except Exception:
                continue

    logger.success(f"ä»å·¥ä½œè¡¨ '{sheet_name}' æ‰¾åˆ° {len(valid_records)} æ¡æœ‰æ•ˆè®°å½•")
    return valid_records

def show_config_info():
    """æ˜¾ç¤ºé…ç½®ä¿¡æ¯"""
    logger.info("å½“å‰é…ç½®:")
    logger.info(f"  æ”¯æŒçš„å·¥ä½œè¡¨: {', '.join(CONFIG['sheet_names'])}")
    logger.info(f"  å¤„ç†æ¨¡å¼: {'å¤„ç†æ‰€æœ‰å·¥ä½œè¡¨' if CONFIG['process_all_sheets'] else 'å¤„ç†ç¬¬ä¸€ä¸ªå¯ç”¨å·¥ä½œè¡¨'}")
    if CONFIG['target_sheet']:
        logger.info(f"  æŒ‡å®šå·¥ä½œè¡¨: {CONFIG['target_sheet']}")
    logger.info(f"  ç­›é€‰æ¨¡å¼: {CONFIG['filter_mode']}")
    logger.info(f"  è½¯ä»¶å…³é”®è¯: {', '.join(CONFIG['software_keywords'])}")
    logger.info(f"  æ‰¹æ¬¡å¤§å°: {CONFIG['batch_size']}")
    logger.info(f"  è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if CONFIG['debug_mode'] else 'å…³é—­'}")
    logger.info(f"  è¿›åº¦æ˜¾ç¤º: {'å¼€å¯' if CONFIG['show_progress'] else 'å…³é—­'}")
    logger.info("ğŸ’¡ æç¤º: é—®é¢˜åˆ†ç±»åŒ…å«'è½¯ä»¶'çš„è®°å½•ä¼šè¢«å¤„ç†")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("WPSè¡¨æ ¼æ•°æ®ä¸Šä¼ å·¥å…· - ä¼˜åŒ–ç‰ˆ")
    print("ä¸“é—¨å¤„ç†åŒ…å«'è½¯ä»¶'å…³é”®è¯çš„é—®é¢˜åˆ†ç±»æ•°æ®")
    print("=" * 60)

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    show_config_info()

    try:
        # 1. æµ‹è¯•æœåŠ¡å™¨è¿æ¥
        logger.info("æµ‹è¯•æœåŠ¡å™¨è¿æ¥")
        response = requests.get('http://114.55.118.105', timeout=CONFIG['timeout'])
        if response.status_code != 200:
            logger.error("æœåŠ¡å™¨è¿æ¥å¤±è´¥")
            return False
        logger.success("æœåŠ¡å™¨è¿æ¥æˆåŠŸ")

        # 2. è·å–å½“å‰æ•°æ®åº“çŠ¶æ€
        get_database_status()

        # 3. è¯»å–å’Œå¤„ç†WPSæ•°æ®
        logger.info("è¯»å–WPSè¡¨æ ¼æ•°æ®")

        all_valid_records = []
        processed_sheets = []

        # ç¡®å®šè¦å¤„ç†çš„å·¥ä½œè¡¨
        if CONFIG['target_sheet']:
            sheets_to_process = [CONFIG['target_sheet']]
        elif CONFIG['process_all_sheets']:
            sheets_to_process = CONFIG['sheet_names']
        else:
            sheets_to_process = CONFIG['sheet_names']

        # å¤„ç†æ¯ä¸ªå·¥ä½œè¡¨
        for sheet_name in sheets_to_process:
            df = read_sheet_data(sheet_name)
            if df is not None:
                valid_records = process_sheet_data(df, sheet_name)
                if valid_records:
                    all_valid_records.extend(valid_records)
                    processed_sheets.append(sheet_name)

                    if not CONFIG['process_all_sheets']:
                        break

        if not all_valid_records:
            logger.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆè®°å½•")
            logger.info("è¯·ç¡®ä¿è¡¨æ ¼ä¸­å­˜åœ¨ä»¥ä¸‹å·¥ä½œè¡¨ä¹‹ä¸€:")
            for sheet_name in CONFIG['sheet_names']:
                logger.info(f"   - {sheet_name}")
            return False

        logger.success(f"æ€»å…±å¤„ç†äº† {len(processed_sheets)} ä¸ªå·¥ä½œè¡¨: {', '.join(processed_sheets)}")
        logger.success(f"æ€»å…±æ‰¾åˆ° {len(all_valid_records)} æ¡æœ‰æ•ˆè®°å½•")

        # 4. æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯
        logger.info("æ•°æ®æ‘˜è¦:")

        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for record in all_valid_records:
            category = record.get('problem_category', 'æœªçŸ¥åˆ†ç±»')
            category_stats[category] = category_stats.get(category, 0) + 1

        logger.info("åˆ†ç±»ç»Ÿè®¡:")
        for category, count in sorted(category_stats.items()):
            logger.info(f"  {category}: {count} æ¡")

        # æ˜¾ç¤ºå‰3æ¡è®°å½•è¯¦æƒ…
        logger.info("è®°å½•è¯¦æƒ…ï¼ˆå‰3æ¡ï¼‰:")
        for i, record in enumerate(all_valid_records[:3], 1):
            project_name = record.get('project_name', 'æœªçŸ¥é¡¹ç›®')
            problem_description = record.get('problem_description', 'æ— æè¿°')
            status = record.get('status', 'æœªçŸ¥çŠ¶æ€')
            category = record.get('problem_category', 'æœªçŸ¥åˆ†ç±»')
            logger.info(f"  {i}. {project_name}: {problem_description[:50]}... (çŠ¶æ€: {status}, åˆ†ç±»: {category})")

        if len(all_valid_records) > 3:
            logger.info(f"  ... è¿˜æœ‰ {len(all_valid_records) - 3} æ¡è®°å½•")

        # 5. åˆ†æ‰¹ä¸Šä¼ 
        logger.info("å¼€å§‹ä¸Šä¼ æ•°æ®")
        batch_size = CONFIG['batch_size']
        total_batches = (len(all_valid_records) + batch_size - 1) // batch_size
        successful_uploads = 0
        skipped_uploads = 0  # æ–°å¢ï¼šè·³è¿‡è®¡æ•°
        failed_uploads = 0

        for i in range(0, len(all_valid_records), batch_size):
            batch = all_valid_records[i:i + batch_size]
            batch_num = (i // batch_size) + 1

            # æ˜¾ç¤ºè¿›åº¦
            show_progress(batch_num, total_batches, "ä¸Šä¼ è¿›åº¦")

            result = upload_batch(batch, batch_num, total_batches)
            if result:
                successful_uploads += result.get('success', 0)
                skipped_uploads += result.get('skipped', 0)
                failed_uploads += result.get('failed', 0)
            else:
                failed_uploads += len(batch)

        # 6. è¾“å‡ºç»“æœ
        total_time = logger.get_elapsed_time()

        logger.info("=" * 60)
        logger.info("ä¸Šä¼ å®Œæˆæ€»ç»“")
        logger.info(f"â±ï¸  æ€»è€—æ—¶: {total_time}")
        logger.info(f"ğŸ“Š ä¸Šä¼ ç»“æœ:")

        if successful_uploads > 0:
            logger.success(f"  âœ… æ–°å¢: {successful_uploads} æ¡")

        if skipped_uploads > 0:
            logger.info(f"  â­ï¸  è·³è¿‡: {skipped_uploads} æ¡ (æ•°æ®å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸Šä¼ )")

        if failed_uploads > 0:
            logger.warning(f"  âŒ å¤±è´¥: {failed_uploads} æ¡")

        # å¤„ç†å…¨éƒ¨è·³è¿‡çš„ç‰¹æ®Šæƒ…å†µ
        if skipped_uploads == len(all_valid_records) and failed_uploads == 0:
            logger.success("âœ… æ•°æ®éªŒè¯å®Œæˆï¼æ‰€æœ‰è®°å½•éƒ½å·²åœ¨æ•°æ®åº“ä¸­")
        elif successful_uploads == 0 and skipped_uploads == 0 and failed_uploads > 0:
            logger.error("âŒ ä¸Šä¼ å¤±è´¥ï¼Œæ‰€æœ‰è®°å½•éƒ½æœªèƒ½å¤„ç†")
        elif successful_uploads > 0:
            logger.success("âœ… æ•°æ®ä¸Šä¼ æˆåŠŸï¼")

        # 7. è·å–æœ€ç»ˆçŠ¶æ€
        logger.info("æœ€ç»ˆæ•°æ®åº“çŠ¶æ€:")
        get_database_status()

        return successful_uploads > 0 or skipped_uploads > 0

    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("å¼€å§‹æ‰§è¡ŒWPSè¡¨æ ¼æ•°æ®ä¸Šä¼ ...")
    success = main()

    if success:
        logger.success("âœ… å¤„ç†å®Œæˆ! æ•°æ®å·²éªŒè¯/ä¿å­˜åˆ°æ•°æ®åº“")
    else:
        logger.error("âŒ å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    print("\næŒ‰ä»»æ„é”®é€€å‡º...")
    try:
        input()
    except:
        pass
