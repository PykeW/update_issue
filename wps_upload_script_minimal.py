#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WPSè¡¨æ ¼ä¸Šä¼ è„šæœ¬ - å¢å¼ºç‰ˆ
ä¸“é—¨å¤„ç†åŒ…å«"è½¯ä»¶"å…³é”®è¯çš„é—®é¢˜åˆ†ç±»æ•°æ®
åœ¨WPSç¯å¢ƒä¸‹è¿è¡Œï¼Œè´Ÿè´£æ•°æ®ä¸Šä¼ åˆ°æœåŠ¡å™¨
"""

import requests
from datetime import datetime

# ==================== é…ç½®ä¿¡æ¯ ====================
CONFIG = {
    'server_url': 'http://114.55.118.105/api/wps/upload',
    'target_category': 'è½¯ä»¶',
    'batch_size': 50,
    'timeout': 30,
    'sheet_names': ['è½¯ä»¶ç®—æ³•æ±‡æ€»', 'é—®é¢˜æ¸…å•', 'è®®é¢˜æ¸…å•', 'é—®é¢˜æ±‡æ€»'],  # æ”¯æŒçš„å·¥ä½œè¡¨åç§°
    'process_all_sheets': True,  # æ˜¯å¦å¤„ç†æ‰€æœ‰å·¥ä½œè¡¨
    'target_sheet': None,  # æŒ‡å®šç›®æ ‡å·¥ä½œè¡¨ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹
    'software_keywords': ['è½¯ä»¶'],  # è½¯ä»¶ç›¸å…³å…³é”®è¯
    'filter_mode': 'software'  # ç­›é€‰æ¨¡å¼: 'software'(è½¯ä»¶ç›¸å…³), 'all'(æ‰€æœ‰è®°å½•)
}

def is_empty_value(value):
    """åˆ¤æ–­å€¼æ˜¯å¦ä¸ºç©º"""
    if value is None:
        return True
    str_value = str(value).strip().lower()
    return str_value in ['', 'nan', 'none', 'null']

def clean_string_value(value):
    """æ¸…ç†å­—ç¬¦ä¸²å€¼"""
    if is_empty_value(value):
        return ''
    return str(value).strip()

def is_valid_software_record(problem_category):
    """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è½¯ä»¶è®°å½•"""
    if is_empty_value(problem_category):
        return False
    category = clean_string_value(problem_category)
    # åªåŒ¹é…åŒ…å«"è½¯ä»¶"ä¸¤ä¸ªå­—çš„è®°å½•
    return 'è½¯ä»¶' in category

def is_valid_record(problem_category, filter_mode):
    """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆè®°å½•"""
    if is_empty_value(problem_category):
        return False

    if filter_mode == 'all':
        return True
    elif filter_mode == 'software':
        return is_valid_software_record(problem_category)
    else:
        return True

def transform_record(row_data):
    """è½¬æ¢å•æ¡è®°å½•"""
    record = {}

    # å­—æ®µæ˜ å°„
    field_mapping = {
        'é¡¹ç›®åç§°': 'project_name',
        'é—®é¢˜åˆ†ç±»': 'problem_category',
        'ä¸¥é‡ç¨‹åº¦': 'severity_level',
        'é—®é¢˜/éœ€æ±‚æè¿°': 'problem_description',
        'è§£å†³æ–¹æ¡ˆ': 'solution',
        'è¡ŒåŠ¨ä¼˜å…ˆçº§': 'action_priority',
        'è¡ŒåŠ¨è®°å½•': 'action_record',
        'å‘èµ·äºº': 'initiator',
        'è´£ä»»äºº': 'responsible_person',
        'çŠ¶æ€': 'status',
        'å¼€å§‹æ—¶é—´': 'start_time',
        'ç›®æ ‡å®Œæˆæ—¶é—´': 'target_completion_time',
        'å®å®Œæ—¶é—´': 'actual_completion_time',
        'å¤‡æ³¨': 'remarks'
    }

    for source_field, target_field in field_mapping.items():
        value = row_data.get(source_field, '')
        record[target_field] = clean_string_value(value)

    # ä¸å†ç”Ÿæˆissue_titleï¼Œç»Ÿä¸€ç”±æ•°æ®åº“å‘GitLabæ¨é€åˆ›å»ºè®®é¢˜

    return record

def upload_batch(batch_data, batch_num, total_batches):
    """ä¸Šä¼ å•æ‰¹æ•°æ®"""
    print(f"ğŸ“¤ ä¸Šä¼ ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch_data)} æ¡)...")

    # è°ƒè¯•ï¼šæ˜¾ç¤ºç¬¬ä¸€æ¡æ•°æ®çš„å­—æ®µ
    if batch_data and batch_num == 1:
        print(f"ğŸ” è°ƒè¯• - ç¬¬ä¸€æ¡æ•°æ®å­—æ®µ: {list(batch_data[0].keys())}")
        print(f"ğŸ” è°ƒè¯• - ç¬¬ä¸€æ¡æ•°æ®å†…å®¹: {batch_data[0]}")

    upload_payload = {
        'table_data': batch_data,
        'client_info': {
            'version': '2.0.0',
            'timestamp': datetime.now().isoformat(),
            'batch_info': {
                'current_batch': batch_num,
                'total_batches': total_batches,
                'batch_size': len(batch_data)
            },
            'source': 'WPSè¡¨æ ¼-å¢å¼ºç‰ˆ'
        }
    }

    try:
        response = requests.post(
            CONFIG['server_url'],
            json=upload_payload,
            headers={'Content-Type': 'application/json'},
            timeout=CONFIG['timeout']
        )

        if response.status_code == 200:
            result = response.json()
            print(f"ğŸ” è°ƒè¯• - æœåŠ¡å™¨å“åº”: {result}")
            if result.get('success'):
                print(f"âœ… ç¬¬ {batch_num} æ‰¹ä¸Šä¼ æˆåŠŸ")
                return True
            else:
                print(f"âŒ ç¬¬ {batch_num} æ‰¹ä¸šåŠ¡å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
        else:
            print(f"âŒ ç¬¬ {batch_num} æ‰¹ä¸Šä¼ å¤±è´¥: HTTP {response.status_code}")
            print(f"ğŸ” è°ƒè¯• - é”™è¯¯å“åº”: {response.text}")
            return False

    except Exception as e:
        print(f"âŒ ç¬¬ {batch_num} æ‰¹ä¸Šä¼ å¼‚å¸¸: {e}")
        return False

# GitLabåŒæ­¥åŠŸèƒ½å·²ç§»é™¤ - æ­¤è„šæœ¬åœ¨WPSç¯å¢ƒä¸‹è¿è¡Œï¼Œä¸è´Ÿè´£GitLabåŒæ­¥

def get_database_status():
    """è·å–æ•°æ®åº“çŠ¶æ€ä¿¡æ¯"""
    print("\nğŸ“Š è·å–æ•°æ®åº“çŠ¶æ€ä¿¡æ¯...")

    try:
        response = requests.get(
            'http://114.55.118.105/api/database/status',
            timeout=CONFIG['timeout']
        )

        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                data = result.get('data', {})
                print(f"ğŸ“‹ æ•°æ®åº“çŠ¶æ€:")
                print(f"  æ€»è®®é¢˜æ•°: {data.get('total_issues', 0)}")
                print(f"  å¼€æ”¾è®®é¢˜: {data.get('open_issues', 0)}")
                print(f"  å…³é—­è®®é¢˜: {data.get('closed_issues', 0)}")
                print(f"  å·²åŒæ­¥è®®é¢˜: {data.get('synced_issues', 0)}")
                return True
            else:
                print(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
        else:
            print(f"âŒ çŠ¶æ€è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
            return False

    except Exception as e:
        print(f"âŒ è·å–çŠ¶æ€å¼‚å¸¸: {e}")
        return False

def read_sheet_data(sheet_name):
    """è¯»å–æŒ‡å®šå·¥ä½œè¡¨çš„æ•°æ®"""
    try:
        print(f"ğŸ¯ è¯»å–å·¥ä½œè¡¨: '{sheet_name}'")
        df = xl('$B:$P', headers=True, sheet_name=sheet_name)  # type: ignore
        if df is not None and not df.empty:
            print(f"âœ… æˆåŠŸè¯»å–å·¥ä½œè¡¨: '{sheet_name}' - {len(df)} è¡Œæ•°æ®")
            return df
        else:
            print(f"âš ï¸ å·¥ä½œè¡¨ '{sheet_name}' ä¸ºç©ºæˆ–æ— æ³•è¯»å–")
            return None
    except Exception as e:
        print(f"âš ï¸ è¯»å–å·¥ä½œè¡¨ '{sheet_name}' å¤±è´¥: {e}")
        return None

def process_sheet_data(df, sheet_name):
    """å¤„ç†å•ä¸ªå·¥ä½œè¡¨çš„æ•°æ®"""
    print(f"\nğŸ“Š å¤„ç†å·¥ä½œè¡¨: '{sheet_name}'")

    # æ¸…æ´—æ•°æ®
    print("ğŸ§¹ æ¸…æ´—æ•°æ®...")
    df = df.dropna(how='all').reset_index(drop=True)

    # æ¸…ç†å­—ç¬¦ä¸²åˆ—
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].fillna('').astype(str)
            df[col] = df[col].replace(['nan', 'NaN', 'null', 'None', 'NULL'], '')
            df[col] = df[col].str.strip()

    # ç­›é€‰æœ‰æ•ˆè®°å½•
    print("ğŸ” ç­›é€‰æœ‰æ•ˆè®°å½•...")
    valid_records = []

    for _, row in df.iterrows():
        problem_category = clean_string_value(row.get('é—®é¢˜åˆ†ç±»', ''))
        project_name = clean_string_value(row.get('é¡¹ç›®åç§°', ''))

        # è·³è¿‡ç©ºè¡Œ
        if is_empty_value(problem_category) and is_empty_value(project_name):
            continue

        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆè®°å½•
        if is_valid_record(problem_category, CONFIG['filter_mode']):
            try:
                row_dict = row.to_dict() if hasattr(row, 'to_dict') else dict(row)
                record = transform_record(row_dict)

                # éªŒè¯å¿…å¡«å­—æ®µ
                if not record.get('project_name'):
                    continue

                # å¦‚æœæ²¡æœ‰é—®é¢˜åˆ†ç±»ï¼Œè®¾ç½®é»˜è®¤å€¼
                if not record.get('problem_category'):
                    record['problem_category'] = 'å…¶ä»–'

                # æ·»åŠ æ¥æºå·¥ä½œè¡¨ä¿¡æ¯
                record['source_sheet'] = sheet_name

                valid_records.append(record)

            except Exception:
                continue

    print(f"âœ… ä»å·¥ä½œè¡¨ '{sheet_name}' æ‰¾åˆ° {len(valid_records)} æ¡æœ‰æ•ˆè®°å½•")
    return valid_records

def show_config_info():
    """æ˜¾ç¤ºé…ç½®ä¿¡æ¯"""
    print("ğŸ“‹ å½“å‰é…ç½®:")
    print(f"  æ”¯æŒçš„å·¥ä½œè¡¨: {', '.join(CONFIG['sheet_names'])}")
    print(f"  å¤„ç†æ¨¡å¼: {'å¤„ç†æ‰€æœ‰å·¥ä½œè¡¨' if CONFIG['process_all_sheets'] else 'å¤„ç†ç¬¬ä¸€ä¸ªå¯ç”¨å·¥ä½œè¡¨'}")
    if CONFIG['target_sheet']:
        print(f"  æŒ‡å®šå·¥ä½œè¡¨: {CONFIG['target_sheet']}")
    print(f"  ç­›é€‰æ¨¡å¼: {CONFIG['filter_mode']}")
    print(f"  è½¯ä»¶å…³é”®è¯: {', '.join(CONFIG['software_keywords'])}")
    print(f"  æ‰¹æ¬¡å¤§å°: {CONFIG['batch_size']}")
    print("ğŸ’¡ æç¤º: é—®é¢˜åˆ†ç±»åŒ…å«'è½¯ä»¶'çš„è®°å½•ä¼šè¢«å¤„ç†")
    print()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("WPSè¡¨æ ¼æ•°æ®ä¸Šä¼ å·¥å…· - å¢å¼ºç‰ˆ")
    print("ä¸“é—¨å¤„ç†åŒ…å«'è½¯ä»¶'å…³é”®è¯çš„é—®é¢˜åˆ†ç±»æ•°æ®")
    print("=" * 50)

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    show_config_info()

    try:
        # 1. æµ‹è¯•æœåŠ¡å™¨è¿æ¥
        print("ğŸŒ æµ‹è¯•æœåŠ¡å™¨è¿æ¥...")
        response = requests.get('http://114.55.118.105', timeout=CONFIG['timeout'])
        if response.status_code != 200:
            print("âŒ æœåŠ¡å™¨è¿æ¥å¤±è´¥")
            return False
        print("âœ… æœåŠ¡å™¨è¿æ¥æˆåŠŸ")

        # 2. è·å–å½“å‰æ•°æ®åº“çŠ¶æ€
        get_database_status()

        # 3. è¯»å–å’Œå¤„ç†WPSæ•°æ®
        print("ğŸ“– è¯»å–WPSè¡¨æ ¼æ•°æ®...")

        all_valid_records = []
        processed_sheets = []

        # ç¡®å®šè¦å¤„ç†çš„å·¥ä½œè¡¨
        if CONFIG['target_sheet']:
            # æŒ‡å®šäº†ç›®æ ‡å·¥ä½œè¡¨
            sheets_to_process = [CONFIG['target_sheet']]
        elif CONFIG['process_all_sheets']:
            # å¤„ç†æ‰€æœ‰æ”¯æŒçš„å·¥ä½œè¡¨
            sheets_to_process = CONFIG['sheet_names']
        else:
            # è‡ªåŠ¨æ£€æµ‹ç¬¬ä¸€ä¸ªå¯ç”¨çš„å·¥ä½œè¡¨
            sheets_to_process = CONFIG['sheet_names']

        # å¤„ç†æ¯ä¸ªå·¥ä½œè¡¨
        for sheet_name in sheets_to_process:
            df = read_sheet_data(sheet_name)
            if df is not None:
                valid_records = process_sheet_data(df, sheet_name)
                if valid_records:
                    all_valid_records.extend(valid_records)
                    processed_sheets.append(sheet_name)

                    # å¦‚æœåªå¤„ç†ä¸€ä¸ªå·¥ä½œè¡¨ï¼Œå¤„ç†å®Œå°±åœæ­¢
                    if not CONFIG['process_all_sheets']:
                        break

        if not all_valid_records:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆè®°å½•")
            print("ğŸ’¡ è¯·ç¡®ä¿è¡¨æ ¼ä¸­å­˜åœ¨ä»¥ä¸‹å·¥ä½œè¡¨ä¹‹ä¸€:")
            for sheet_name in CONFIG['sheet_names']:
                print(f"   - {sheet_name}")
            return False

        print(f"\nâœ… æ€»å…±å¤„ç†äº† {len(processed_sheets)} ä¸ªå·¥ä½œè¡¨: {', '.join(processed_sheets)}")
        print(f"âœ… æ€»å…±æ‰¾åˆ° {len(all_valid_records)} æ¡æœ‰æ•ˆè®°å½•")

        # 4. æ˜¾ç¤ºæ‘˜è¦å’Œè°ƒè¯•ä¿¡æ¯
        print("\nğŸ“¤ å³å°†ä¸Šä¼ çš„æ•°æ®æ‘˜è¦:")

        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        category_stats = {}
        for record in all_valid_records:
            category = record.get('problem_category', 'æœªçŸ¥åˆ†ç±»')
            category_stats[category] = category_stats.get(category, 0) + 1

        print("ğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
        for category, count in sorted(category_stats.items()):
            print(f"  {category}: {count} æ¡")

        print("\nğŸ“‹ è®°å½•è¯¦æƒ…ï¼ˆå‰5æ¡ï¼‰:")
        for i, record in enumerate(all_valid_records[:5], 1):
            project_name = record.get('project_name', 'æœªçŸ¥é¡¹ç›®')
            problem_description = record.get('problem_description', 'æ— æè¿°')
            status = record.get('status', 'æœªçŸ¥çŠ¶æ€')
            category = record.get('problem_category', 'æœªçŸ¥åˆ†ç±»')
            source_sheet = record.get('source_sheet', 'æœªçŸ¥å·¥ä½œè¡¨')
            print(f"  {i}. {project_name}: {problem_description[:50]}... (çŠ¶æ€: {status}, åˆ†ç±»: {category}, æ¥æº: {source_sheet})")

        if len(all_valid_records) > 5:
            print(f"  ... è¿˜æœ‰ {len(all_valid_records) - 5} æ¡è®°å½•")
        print(f"æ€»è®¡: {len(all_valid_records)} æ¡è®°å½•")

        # 5. åˆ†æ‰¹ä¸Šä¼ 
        print("\nğŸš€ å¼€å§‹ä¸Šä¼ æ•°æ®...")
        batch_size = CONFIG['batch_size']
        total_batches = (len(all_valid_records) + batch_size - 1) // batch_size
        successful_uploads = 0

        for i in range(0, len(all_valid_records), batch_size):
            batch = all_valid_records[i:i + batch_size]
            batch_num = (i // batch_size) + 1

            if upload_batch(batch, batch_num, total_batches):
                successful_uploads += len(batch)

        # GitLabåŒæ­¥å·²ç§»é™¤ - ç”±æœåŠ¡å™¨ç«¯å¤„ç†

        # 6. è¾“å‡ºç»“æœ
        success_ratio = successful_uploads / len(all_valid_records)
        print(f"\nğŸ“Š ä¸Šä¼ ç»“æœ: {successful_uploads}/{len(all_valid_records)} æ¡è®°å½•æˆåŠŸ ({success_ratio:.1%})")

        # 10. è·å–æœ€ç»ˆçŠ¶æ€
        print("\nğŸ“Š æœ€ç»ˆæ•°æ®åº“çŠ¶æ€:")
        get_database_status()

        return successful_uploads > 0

    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("å¼€å§‹æ‰§è¡ŒWPSè¡¨æ ¼æ•°æ®ä¸Šä¼ ...")
    success = main()

    if success:
        print("\nğŸ‰ ä¸Šä¼ å®Œæˆ! æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æ•°æ®åº“")
    else:
        print("\nğŸ˜ ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    print("\næŒ‰ä»»æ„é”®é€€å‡º...")
    try:
        input()
    except:
        pass
